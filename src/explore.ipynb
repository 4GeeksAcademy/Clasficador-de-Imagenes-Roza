{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: kagglehub in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (0.3.12)\n",
                        "Requirement already satisfied: packaging in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
                        "Requirement already satisfied: pyyaml in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (6.0.2)\n",
                        "Requirement already satisfied: requests in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (2.32.4)\n",
                        "Requirement already satisfied: tqdm in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.4.2)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (2025.7.14)\n",
                        "Path to dataset files: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\n"
                    ]
                }
            ],
            "source": [
                "!pip install kagglehub\n",
                "import kagglehub\n",
                "\n",
                "path = kagglehub.dataset_download(\"salader/dogs-vs-cats\")\n",
                "\n",
                "print(\"Path to dataset files:\", path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-07-20 21:08:12.093767: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-07-20 21:08:12.105360: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-07-20 21:08:12.291379: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-07-20 21:08:12.412597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1753045692.478315    9653 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1753045692.493621    9653 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1753045692.604959    9653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753045692.604984    9653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753045692.604986    9653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753045692.604988    9653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-07-20 21:08:12.625822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Configuration ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "IMAGE_WIDTH, IMAGE_HEIGHT = 200, 200\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "\n",
                "# Define directories relative to the current working directory\n",
                "BASE_DATA_DIR = 'dogs_vs_cats_dataset' # This is in your project root, as seen in screenshot\n",
                "TRAIN_DIR = os.path.join(BASE_DATA_DIR, 'train')\n",
                "VALIDATION_DIR = os.path.join(BASE_DATA_DIR, 'validation')\n",
                "\n",
                "MODEL_SAVE_PATH = 'trained_models/dogs_vs_cats_vgg_like.h5'\n",
                "CHECKPOINT_FILEPATH = 'trained_models/best_model_checkpoint.h5'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Step 1: Loading the dataset using kagglehub ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset downloaded to: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\n",
                        "Contents of downloaded path (/home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1):\n",
                        " - train\n",
                        " - dogs_vs_cats\n",
                        " - test\n",
                        "DEBUG: Directory '/home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1/dogs_vs_cats/train' exists but contains no common image files.\n",
                        "DEBUG: Directory '/home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1/train' exists but contains no common image files.\n",
                        "DEBUG: Directory '/home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1' exists but contains no common image files.\n",
                        "ERROR: Could not find any common image files in expected locations within the downloaded dataset.\n",
                        "Please manually inspect the contents of:\n",
                        "  /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\n",
                        "To locate the actual directory containing the dog/cat images (e.g., 'train').\n",
                        "\n",
                        "--- Preparing directory structure for ImageDataGenerator ---\n",
                        "DEBUG: Total image files found in 'None' before splitting: 0\n",
                        "CRITICAL ERROR: No image files found in the source directory after download. Cannot proceed with data splitting.\n",
                        "Splitting 0 images: 0 for training, 0 for validation.\n",
                        "\n",
                        "--- Data Copying Summary ---\n",
                        "  Training Dogs Copied: 0\n",
                        "  Training Cats Copied: 0\n",
                        "  Validation Dogs Copied: 0\n",
                        "  Validation Cats Copied: 0\n",
                        "  Total Successfully Copied: 0\n",
                        "  Total Files in Source: 0\n",
                        "  Files Skipped/Failed to Copy: 0\n",
                        "Dataset structuring attempt finished.\n"
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    download_path = kagglehub.dataset_download(\"salader/dogs-vs-cats\")\n",
                "    print(f\"Dataset downloaded to: {download_path}\")\n",
                "\n",
                "    print(f\"Contents of downloaded path ({download_path}):\")\n",
                "    for item in os.listdir(download_path):\n",
                "        print(f\" - {item}\")\n",
                "\n",
                "    potential_source_dirs = [\n",
                "        os.path.join(download_path, 'dogs_vs_cats', 'train'), # Path identified from your last output\n",
                "        os.path.join(download_path, 'train'),\n",
                "        download_path\n",
                "    ]\n",
                "\n",
                "    source_images_dir = None\n",
                "    for p_dir in potential_source_dirs:\n",
                "        if os.path.isdir(p_dir):\n",
                "            if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in os.listdir(p_dir)): # Check for more image types\n",
                "                source_images_dir = p_dir\n",
                "                break\n",
                "            else:\n",
                "                print(f\"DEBUG: Directory '{p_dir}' exists but contains no common image files.\")\n",
                "\n",
                "    if source_images_dir is None:\n",
                "        print(\"ERROR: Could not find any common image files in expected locations within the downloaded dataset.\")\n",
                "        print(\"Please manually inspect the contents of:\")\n",
                "        print(f\"  {download_path}\")\n",
                "        print(\"To locate the actual directory containing the dog/cat images (e.g., 'train').\")\n",
                "        exit()\n",
                "    else:\n",
                "        print(f\"Identified source images directory: {source_images_dir}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Error downloading dataset: {e}\")\n",
                "    print(\"Please ensure 'kagglehub' is installed and your Kaggle API credentials are correctly set up (kaggle.json in ~/.kaggle/).\")\n",
                "    exit()\n",
                "\n",
                "# --- Prepare Directory Structure for ImageDataGenerator ---\n",
                "print(\"\\n--- Preparing directory structure for ImageDataGenerator ---\")\n",
                "# Create base directories in your project's dogs_vs_cats_dataset folder\n",
                "os.makedirs(os.path.join(TRAIN_DIR, 'dogs'), exist_ok=True)\n",
                "os.makedirs(os.path.join(TRAIN_DIR, 'cats'), exist_ok=True)\n",
                "os.makedirs(os.path.join(VALIDATION_DIR, 'dogs'), exist_ok=True)\n",
                "os.makedirs(os.path.join(VALIDATION_DIR, 'cats'), exist_ok=True)\n",
                "\n",
                "# List all image files from the identified source directory\n",
                "all_image_files = [f for f in os.listdir(source_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "random.shuffle(all_image_files)\n",
                "\n",
                "print(f\"DEBUG: Total image files found in '{source_images_dir}' before splitting: {len(all_image_files)}\")\n",
                "\n",
                "if not all_image_files:\n",
                "    print(\"CRITICAL ERROR: No image files found in the source directory after download. Cannot proceed with data splitting.\")\n",
                "    exit() # Exit early if no files are found\n",
                "\n",
                "train_split_ratio = 0.8\n",
                "num_train_images = int(len(all_image_files) * train_split_ratio)\n",
                "\n",
                "print(f\"Splitting {len(all_image_files)} images: {num_train_images} for training, {len(all_image_files) - num_train_images} for validation.\")\n",
                "\n",
                "copied_train_dogs = 0\n",
                "copied_train_cats = 0\n",
                "copied_val_dogs = 0\n",
                "copied_val_cats = 0\n",
                "failed_copies = 0\n",
                "\n",
                "for i, img_name in enumerate(all_image_files):\n",
                "    src_full_path = os.path.join(source_images_dir, img_name)\n",
                "    dst_full_path = None\n",
                "\n",
                "    # Determine destination based on filename and split\n",
                "    if 'dog' in img_name.lower():\n",
                "        if i < num_train_images:\n",
                "            dst_full_path = os.path.join(TRAIN_DIR, 'dogs', img_name)\n",
                "            copied_train_dogs += 1\n",
                "        else:\n",
                "            dst_full_path = os.path.join(VALIDATION_DIR, 'dogs', img_name)\n",
                "            copied_val_dogs += 1\n",
                "    elif 'cat' in img_name.lower():\n",
                "        if i < num_train_images:\n",
                "            dst_full_path = os.path.join(TRAIN_DIR, 'cats', img_name)\n",
                "            copied_train_cats += 1\n",
                "        else:\n",
                "            dst_full_path = os.path.join(VALIDATION_DIR, 'cats', img_name)\n",
                "            copied_val_cats += 1\n",
                "    else:\n",
                "        print(f\"WARNING: Skipping '{img_name}' (neither 'dog' nor 'cat' in filename).\")\n",
                "        failed_copies += 1\n",
                "        continue # Skip to next file\n",
                "\n",
                "    if dst_full_path:\n",
                "        try:\n",
                "            shutil.copy(src_full_path, dst_full_path)\n",
                "        except Exception as e:\n",
                "            print(f\"ERROR: Failed to copy '{src_full_path}' to '{dst_full_path}': {e}\")\n",
                "            failed_copies += 1 # Count as failed copy\n",
                "\n",
                "print(f\"\\n--- Data Copying Summary ---\")\n",
                "print(f\"  Training Dogs Copied: {copied_train_dogs}\")\n",
                "print(f\"  Training Cats Copied: {copied_train_cats}\")\n",
                "print(f\"  Validation Dogs Copied: {copied_val_dogs}\")\n",
                "print(f\"  Validation Cats Copied: {copied_val_cats}\")\n",
                "print(f\"  Total Successfully Copied: {copied_train_dogs + copied_train_cats + copied_val_dogs + copied_val_cats}\")\n",
                "print(f\"  Total Files in Source: {len(all_image_files)}\")\n",
                "print(f\"  Files Skipped/Failed to Copy: {failed_copies}\")\n",
                "print(\"Dataset structuring attempt finished.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Step 2: Visualize the input information ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Displaying 9 sample dogs images from dogs_vs_cats_dataset/train...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 800x800 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Displaying 9 sample cats images from dogs_vs_cats_dataset/train...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 800x800 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Setting up ImageDataGenerator ---\n",
                        "Found 0 images belonging to 2 classes.\n",
                        "Found 0 images belonging to 2 classes.\n",
                        "Class indices: {'cats': 0, 'dogs': 1}\n"
                    ]
                }
            ],
            "source": [
                "def plot_sample_images(directory, class_name, num_images=9):\n",
                "    \"\"\"Plots a grid of sample images from a specified directory and class.\"\"\"\n",
                "    print(f\"Displaying {num_images} sample {class_name} images from {directory}...\")\n",
                "    class_path = os.path.join(directory, class_name)\n",
                "    image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg')]\n",
                "    random.shuffle(image_files) # Shuffle to get different samples each time\n",
                "\n",
                "    plt.figure(figsize=(8, 8))\n",
                "    plt.suptitle(f\"Sample {class_name.capitalize()} Images\", fontsize=16)\n",
                "    for i in range(min(num_images, len(image_files))):\n",
                "        img_path = os.path.join(class_path, image_files[i])\n",
                "        img = mpimg.imread(img_path)\n",
                "        plt.subplot(3, 3, i + 1)\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    plt.show()\n",
                "\n",
                "plot_sample_images(TRAIN_DIR, 'dogs')\n",
                "plot_sample_images(TRAIN_DIR, 'cats')\n",
                "\n",
                "# --- Create ImageDataGenerator objects ---\n",
                "print(\"\\n--- Setting up ImageDataGenerator ---\")\n",
                "\n",
                "# Data Augmentation for training data\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,             # Normalize pixel values to [0, 1]\n",
                "    rotation_range=20,          # Randomly rotate images by 20 degrees\n",
                "    width_shift_range=0.2,      # Randomly shift images horizontally\n",
                "    height_shift_range=0.2,     # Randomly shift images vertically\n",
                "    shear_range=0.2,            # Apply shear transformations\n",
                "    zoom_range=0.2,             # Apply random zoom\n",
                "    horizontal_flip=True,       # Randomly flip images horizontally\n",
                "    fill_mode='nearest'         # Fill in newly created pixels\n",
                ")\n",
                "\n",
                "# Only rescaling for validation data (no augmentation)\n",
                "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# Flow images from directories\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary', # For 2 classes (dog/cat)\n",
                "    shuffle=True # Shuffle training data\n",
                ")\n",
                "\n",
                "validation_generator = validation_datagen.flow_from_directory(\n",
                "    VALIDATION_DIR,\n",
                "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=False # Do not shuffle validation data for consistent evaluation\n",
                ")\n",
                "\n",
                "print(f\"Class indices: {train_generator.class_indices}\") # {'cats': 0, 'dogs': 1} or vice-versa\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
