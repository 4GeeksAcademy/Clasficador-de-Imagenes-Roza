{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: kagglehub in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (0.3.12)\n",
                        "Requirement already satisfied: packaging in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
                        "Requirement already satisfied: pyyaml in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (6.0.2)\n",
                        "Requirement already satisfied: requests in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (2.32.4)\n",
                        "Requirement already satisfied: tqdm in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.4.2)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Clasficador-de-Imagenes-Roza/.venv/lib/python3.11/site-packages (from requests->kagglehub) (2025.7.14)\n",
                        "Path to dataset files: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\n"
                    ]
                }
            ],
            "source": [
                "!pip install kagglehub\n",
                "import kagglehub\n",
                "\n",
                "path = kagglehub.dataset_download(\"salader/dogs-vs-cats\")\n",
                "\n",
                "print(\"Path to dataset files:\", path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-07-20 21:18:05.442569: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-07-20 21:18:05.443734: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-07-20 21:18:05.447423: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-07-20 21:18:05.456869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1753046285.472455   12840 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1753046285.476867   12840 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1753046285.489502   12840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753046285.489527   12840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753046285.489529   12840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1753046285.489530   12840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-07-20 21:18:05.493717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "import zipfile "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Configuration ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "IMAGE_WIDTH, IMAGE_HEIGHT = 200, 200\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "\n",
                "# Define local directories for our structured dataset\n",
                "BASE_DATA_DIR = 'dogs_vs_cats_dataset'\n",
                "TRAIN_DIR = os.path.join(BASE_DATA_DIR, 'train')\n",
                "VALIDATION_DIR = os.path.join(BASE_DATA_DIR, 'validation')\n",
                "\n",
                "# Model saving path\n",
                "MODEL_SAVE_PATH = 'trained_models/dogs_vs_cats_vgg_like.h5'\n",
                "CHECKPOINT_FILEPATH = 'trained_models/best_model_checkpoint.h5'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Step 1: Loading the dataset using kagglehub ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset downloaded to: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\n",
                        "Identified source directories for images:\n",
                        "  Cats: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1/dogs_vs_cats/train/cats\n",
                        "  Dogs: /home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1/dogs_vs_cats/train/dogs\n",
                        "\n",
                        "--- Preparing local directory structure for ImageDataGenerator ---\n",
                        "Removing existing 'dogs_vs_cats_dataset' directory for a clean start...\n",
                        "Found 10000 cat images and 10000 dog images in source.\n",
                        "Dataset successfully structured into local train/validation directories.\n",
                        "  Training Cats: 8000\n",
                        "  Training Dogs: 8000\n",
                        "  Validation Cats: 2000\n",
                        "  Validation Dogs: 2000\n"
                    ]
                }
            ],
            "source": [
                "download_path = None\n",
                "\n",
                "try:\n",
                "    download_path = kagglehub.dataset_download(\"salader/dogs-vs-cats\")\n",
                "    print(f\"Dataset downloaded to: {download_path}\")\n",
                "\n",
                "    # Based on your latest 'ls -l' output, the raw images are directly within\n",
                "    # 'dogs_vs_cats/train/' organized into 'cats/' and 'dogs/' subfolders.\n",
                "    # We will use this 'train' folder from the cache as our source.\n",
                "    SOURCE_TRAIN_CATS_DIR = os.path.join(download_path, 'dogs_vs_cats', 'train', 'cats')\n",
                "    SOURCE_TRAIN_DOGS_DIR = os.path.join(download_path, 'dogs_vs_cats', 'train', 'dogs')\n",
                "\n",
                "    if not os.path.isdir(SOURCE_TRAIN_CATS_DIR) or not os.path.isdir(SOURCE_TRAIN_DOGS_DIR):\n",
                "        print(f\"CRITICAL ERROR: Expected source directories not found or incomplete:\")\n",
                "        print(f\"  Cats source: {SOURCE_TRAIN_CATS_DIR}\")\n",
                "        print(f\"  Dogs source: {SOURCE_TRAIN_DOGS_DIR}\")\n",
                "        print(\"Please manually verify the structure of the KaggleHub downloaded dataset.\")\n",
                "        exit()\n",
                "\n",
                "    print(f\"Identified source directories for images:\")\n",
                "    print(f\"  Cats: {SOURCE_TRAIN_CATS_DIR}\")\n",
                "    print(f\"  Dogs: {SOURCE_TRAIN_DOGS_DIR}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Error during dataset download or initial path identification: {e}\")\n",
                "    print(\"Please ensure 'kagglehub' is installed and your Kaggle API credentials are correctly set up (kaggle.json in ~/.kaggle/).\")\n",
                "    exit()\n",
                "\n",
                "# --- Prepare local directory structure for ImageDataGenerator ---\n",
                "print(\"\\n--- Preparing local directory structure for ImageDataGenerator ---\")\n",
                "\n",
                "# Clean up existing structure if it exists to avoid old files\n",
                "if os.path.exists(BASE_DATA_DIR):\n",
                "    print(f\"Removing existing '{BASE_DATA_DIR}' directory for a clean start...\")\n",
                "    shutil.rmtree(BASE_DATA_DIR)\n",
                "\n",
                "os.makedirs(os.path.join(TRAIN_DIR, 'dogs'), exist_ok=True)\n",
                "os.makedirs(os.path.join(TRAIN_DIR, 'cats'), exist_ok=True)\n",
                "os.makedirs(os.path.join(VALIDATION_DIR, 'dogs'), exist_ok=True)\n",
                "os.makedirs(os.path.join(VALIDATION_DIR, 'cats'), exist_ok=True)\n",
                "\n",
                "# List all image files from the source 'cats' and 'dogs' directories\n",
                "all_cat_files = [f for f in os.listdir(SOURCE_TRAIN_CATS_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "all_dog_files = [f for f in os.listdir(SOURCE_TRAIN_DOGS_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "\n",
                "random.shuffle(all_cat_files)\n",
                "random.shuffle(all_dog_files)\n",
                "\n",
                "print(f\"Found {len(all_cat_files)} cat images and {len(all_dog_files)} dog images in source.\")\n",
                "\n",
                "# Define split ratio (e.g., 80% train, 20% validation)\n",
                "train_split_ratio = 0.8\n",
                "\n",
                "# Distribute cat images\n",
                "num_train_cats = int(len(all_cat_files) * train_split_ratio)\n",
                "for i, img_name in enumerate(all_cat_files):\n",
                "    src_path = os.path.join(SOURCE_TRAIN_CATS_DIR, img_name)\n",
                "    if i < num_train_cats:\n",
                "        dst_path = os.path.join(TRAIN_DIR, 'cats', img_name)\n",
                "    else:\n",
                "        dst_path = os.path.join(VALIDATION_DIR, 'cats', img_name)\n",
                "    try:\n",
                "        shutil.copy(src_path, dst_path)\n",
                "    except Exception as e:\n",
                "        print(f\"ERROR: Could not copy cat image '{img_name}': {e}\")\n",
                "\n",
                "# Distribute dog images\n",
                "num_train_dogs = int(len(all_dog_files) * train_split_ratio)\n",
                "for i, img_name in enumerate(all_dog_files):\n",
                "    src_path = os.path.join(SOURCE_TRAIN_DOGS_DIR, img_name)\n",
                "    if i < num_train_dogs:\n",
                "        dst_path = os.path.join(TRAIN_DIR, 'dogs', img_name)\n",
                "    else:\n",
                "        dst_path = os.path.join(VALIDATION_DIR, 'dogs', img_name)\n",
                "    try:\n",
                "        shutil.copy(src_path, dst_path)\n",
                "    except Exception as e:\n",
                "        print(f\"ERROR: Could not copy dog image '{img_name}': {e}\")\n",
                "\n",
                "print(\"Dataset successfully structured into local train/validation directories.\")\n",
                "print(f\"  Training Cats: {len(os.listdir(os.path.join(TRAIN_DIR, 'cats')))}\")\n",
                "print(f\"  Training Dogs: {len(os.listdir(os.path.join(TRAIN_DIR, 'dogs')))}\")\n",
                "print(f\"  Validation Cats: {len(os.listdir(os.path.join(VALIDATION_DIR, 'cats')))}\")\n",
                "print(f\"  Validation Dogs: {len(os.listdir(os.path.join(VALIDATION_DIR, 'dogs')))}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# --- Step 2: Visualize the input information ---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Displaying 9 sample dogs images from dogs_vs_cats_dataset/train...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 800x800 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Displaying 9 sample cats images from dogs_vs_cats_dataset/train...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 800x800 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Setting up ImageDataGenerator ---\n",
                        "Found 0 images belonging to 2 classes.\n",
                        "Found 0 images belonging to 2 classes.\n",
                        "Class indices: {'cats': 0, 'dogs': 1}\n"
                    ]
                }
            ],
            "source": [
                "def plot_sample_images(directory, class_name, num_images=9):\n",
                "    \"\"\"Plots a grid of sample images from a specified directory and class.\"\"\"\n",
                "    print(f\"Displaying {num_images} sample {class_name} images from {directory}...\")\n",
                "    class_path = os.path.join(directory, class_name)\n",
                "    image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg')]\n",
                "    random.shuffle(image_files) # Shuffle to get different samples each time\n",
                "\n",
                "    plt.figure(figsize=(8, 8))\n",
                "    plt.suptitle(f\"Sample {class_name.capitalize()} Images\", fontsize=16)\n",
                "    for i in range(min(num_images, len(image_files))):\n",
                "        img_path = os.path.join(class_path, image_files[i])\n",
                "        img = mpimg.imread(img_path)\n",
                "        plt.subplot(3, 3, i + 1)\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    plt.show()\n",
                "\n",
                "plot_sample_images(TRAIN_DIR, 'dogs')\n",
                "plot_sample_images(TRAIN_DIR, 'cats')\n",
                "\n",
                "# --- Create ImageDataGenerator objects ---\n",
                "print(\"\\n--- Setting up ImageDataGenerator ---\")\n",
                "\n",
                "# Data Augmentation for training data\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,             # Normalize pixel values to [0, 1]\n",
                "    rotation_range=20,          # Randomly rotate images by 20 degrees\n",
                "    width_shift_range=0.2,      # Randomly shift images horizontally\n",
                "    height_shift_range=0.2,     # Randomly shift images vertically\n",
                "    shear_range=0.2,            # Apply shear transformations\n",
                "    zoom_range=0.2,             # Apply random zoom\n",
                "    horizontal_flip=True,       # Randomly flip images horizontally\n",
                "    fill_mode='nearest'         # Fill in newly created pixels\n",
                ")\n",
                "\n",
                "# Only rescaling for validation data (no augmentation)\n",
                "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# Flow images from directories\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary', # For 2 classes (dog/cat)\n",
                "    shuffle=True # Shuffle training data\n",
                ")\n",
                "\n",
                "validation_generator = validation_datagen.flow_from_directory(\n",
                "    VALIDATION_DIR,\n",
                "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=False # Do not shuffle validation data for consistent evaluation\n",
                ")\n",
                "\n",
                "print(f\"Class indices: {train_generator.class_indices}\") # {'cats': 0, 'dogs': 1} or vice-versa\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
